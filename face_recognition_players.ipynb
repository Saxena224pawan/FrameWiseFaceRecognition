{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "face_recognition_players.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saxena224pawan/FrameWiseFaceRecognition/blob/master/face_recognition_players.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Uv7SBvFsaSbC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#For this notebook\n",
        "#please add the 2 shared folders into drive\n",
        "#Run the code line below to get notebook permission for using drive\n",
        "#video credits: https://www.youtube.com/watch?v=crYEEf3g3us"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Dwh72Qibapeh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f8a30474-be2a-4d47-ffed-751c1a06917a"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\",force_remount=True)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xNRHBNzo4hCJ",
        "colab_type": "code",
        "outputId": "0b609a66-b954-4591-e672-464f9a273c4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "cell_type": "code",
      "source": [
        "# THis may take a while to complete\n",
        "!pip install cmake\n",
        "\n",
        "!pip install face_recognition --no-cache\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cmake in /usr/local/lib/python3.6/dist-packages (3.12.0)\n",
            "Collecting face_recognition\n",
            "  Downloading https://files.pythonhosted.org/packages/3f/ed/ad9a28042f373d4633fc8b49109b623597d6f193d3bbbef7780a5ee8eef2/face_recognition-1.2.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (19.16.0)\n",
            "Collecting face-recognition-models>=0.3.0 (from face_recognition)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/3b/4fd8c534f6c0d1b80ce0973d01331525538045084c73c153ee6df20224cf/face_recognition_models-0.3.0.tar.gz (100.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 100.2MB 37.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click>=6.0 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from face_recognition) (1.14.6)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from face_recognition) (4.1.1)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->face_recognition) (0.46)\n",
            "Installing collected packages: face-recognition-models, face-recognition\n",
            "  Running setup.py install for face-recognition-models ... \u001b[?25ldone\n",
            "\u001b[?25hSuccessfully installed face-recognition-1.2.3 face-recognition-models-0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3CAOdLEH_wIx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# In[2]:\n",
        "\n",
        "\n",
        "import face_recognition\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# In[4]:\n",
        "# We can also add more players for detection \n",
        "# Add the folder for whom reognition needs to be done along with the video sequence\n",
        "kane = face_recognition.load_image_file(\"gdrive/My Drive/framewiseFaceRecognition/kane.png\")\n",
        "kane_face_encoding = face_recognition.face_encodings(kane)[0]\n",
        "cahill = face_recognition.load_image_file(\"gdrive/My Drive/framewiseFaceRecognition/cahill.jpg\")\n",
        "cahill_face_encoding = face_recognition.face_encodings(cahill)[0]\n",
        "input_movie = cv2.VideoCapture(\"gdrive/My Drive/framewiseFaceRecognition/movie.mp4\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dhp0PoAiFck_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "known_face_encodings = [\n",
        "    kane_face_encoding,\n",
        "    cahill_face_encoding\n",
        "]\n",
        "known_face_names = [\n",
        "    \"kane\",\n",
        "    \"cahill\"\n",
        "  \n",
        "]\n",
        "x=0\n",
        "y=0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kchwt5bwHJnH",
        "colab_type": "code",
        "outputId": "00ea0361-5854-462b-c58e-fa307f722eb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "length = int(input_movie.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "length"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2275"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "iSXsugqbq5N6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "Ix1jzxQA_wLc",
        "colab_type": "code",
        "outputId": "7038a5cb-da60-41e6-8f4a-382c03a70ed1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1013
        }
      },
      "cell_type": "code",
      "source": [
        "#THis may take a while to complete\n",
        "import os\n",
        "path =\"gdrive/My Drive/framewiseFaceRecognition/frame_wise_folder/frame_%d\"\n",
        "\n",
        "for i in range(length):\n",
        "    # Grab a single frame of video\n",
        "    ret, frame = input_movie.read()\n",
        "    print(y)\n",
        "    y+=1\n",
        "    rgb_frame = frame[:, :, ::-1]\n",
        "    try:  \n",
        "      os.mkdir(path %y)\n",
        "    except OSError:  \n",
        "      print (\"Creation of the directory %s failed\" % y)\n",
        "    os.mkdir(\"gdrive/My Drive/framewiseFaceRecognition/frame_wise_folder/frame_%d/kane\" %y)  \n",
        "    os.mkdir(\"gdrive/My Drive/framewiseFaceRecognition/frame_wise_folder/frame_%d/cahill\" %y)  \n",
        "    os.mkdir(\"gdrive/My Drive/framewiseFaceRecognition/frame_wise_folder/frame_%d/unknown\" %y)  \n",
        "    \n",
        "    # Find all the faces and face enqcodings in the frame of video\n",
        "    face_locations = face_recognition.face_locations(rgb_frame)\n",
        "    face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
        "    \n",
        "    # Loop through each face in this frame of video\n",
        "    for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
        "        # See if the face is a match for the known face(s)\n",
        "        matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
        "\n",
        "        name = \"unknown\"\n",
        "\n",
        "        # If a match was found in known_face_encodings, just use the first one.\n",
        "        \n",
        "        if True in matches:\n",
        "            first_match_index = matches.index(True)\n",
        "            name = known_face_names[first_match_index]\n",
        "\n",
        "            \n",
        "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
        "        #For small faces\n",
        "        if (bottom-top >= 32 and right-left>=32): \n",
        "          if name ==\"unknown\":\n",
        "              fimage =rgb_frame[top:bottom,left:right]\n",
        "              fimage=cv2.cvtColor(fimage, cv2.COLOR_BGR2RGB)\n",
        "              #cv2.imwrite(\"gdrive/My Drive/video/videos/%s/%d.jpg\" %(name ,x),fimage)\n",
        "              cv2.imwrite(\"gdrive/My Drive/framewiseFaceRecognition/frame_wise_folder/frame_%d/%s/%d.jpg\" %(y,name,x),fimage)\n",
        "              x+=1\n",
        "          else:\n",
        "              fimage =rgb_frame[top:bottom,left:right]\n",
        "              fimage=cv2.cvtColor(fimage, cv2.COLOR_BGR2RGB)\n",
        "              #cv2.imwrite(\"gdrive/My Drive/video/videos/%s/%d.jpg\" %(name, x),fimage)            \n",
        "              cv2.imwrite(\"gdrive/My Drive/framewiseFaceRecognition/frame_wise_folder/frame_%d/%s/%d.jpg\" %(y,name, x),fimage)\n",
        "\n",
        "              x+=1          \n",
        "            \n",
        "        # Draw a label with a name below the face\n",
        "        cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 255, 0), cv2.FILLED)\n",
        "        font = cv2.FONT_HERSHEY_DUPLEX\n",
        "        cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (0, 0, 0), 1)\n",
        "        # Display the resulting image\n",
        "        \n",
        "    "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-60b4f0a999c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mrgb_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ]
    }
  ]
}